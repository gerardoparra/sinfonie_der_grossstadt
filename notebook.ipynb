{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "import soundfile as sf\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple German speech files and extract MFCCs\n",
    "mfcc_list = []\n",
    "\n",
    "directory = os.fsencode('./data/clips')\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".mp3\"):\n",
    "        y, sr = librosa.load(os.path.join('./data/clips', filename), sr=None)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=26)\n",
    "    mfcc_list.append(mfccs.T)\n",
    "\n",
    "# Stack all MFCCs from different files\n",
    "all_mfccs = np.vstack(mfcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 1000  # Adjust length\n",
    "\n",
    "# Fit a GMM with 8 components (adjust for best results)\n",
    "gmm = GaussianMixture(n_components=8, covariance_type=\"full\", random_state=42)\n",
    "gmm.fit(all_mfccs)\n",
    "random_mfccs = gmm.sample(num_frames)[0].T  # Transpose back to (features, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit KDE to each MFCC coefficient separately\n",
    "kde_models = [KernelDensity(kernel=\"gaussian\", bandwidth=0.1).fit(all_mfccs[:, i].reshape(-1, 1))\n",
    "              for i in range(all_mfccs.shape[1])]\n",
    "\n",
    "# Generate random MFCCs using KDE\n",
    "random_mfccs = np.array([kde.sample(num_frames).flatten() for kde in kde_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute delta and delta-delta (acceleration) to enforce smoothness\n",
    "delta_mfccs = librosa.feature.delta(random_mfccs)\n",
    "delta2_mfccs = librosa.feature.delta(random_mfccs, order=2)\n",
    "\n",
    "# Stack for a more speech-like representation\n",
    "generated_mfccs = np.vstack([random_mfccs, delta_mfccs, delta2_mfccs])\n",
    "\n",
    "\n",
    "# Convert random MFCCs back to a Mel spectrogram\n",
    "random_mel_spec = librosa.feature.inverse.mfcc_to_mel(random_mfccs)\n",
    "\n",
    "# Convert Mel spectrogram to STFT (Short-Time Fourier Transform)\n",
    "random_stft = librosa.feature.inverse.mel_to_stft(random_mel_spec, sr=sr)\n",
    "\n",
    "# Reconstruct the waveform using the Griffin-Lim algorithm\n",
    "random_audio = librosa.griffinlim(random_stft)\n",
    "\n",
    "# Design a bandpass filter (simulating vocal tract effects)\n",
    "lowcut = 300  # Hz\n",
    "highcut = 3400  # Hz\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype=\"band\")\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "# Apply the filter to the synthesized speech\n",
    "filtered_audio = butter_bandpass_filter(random_audio, lowcut, highcut, sr)\n",
    "\n",
    "sf.write(\"generated_speech.wav\", filtered_audio, sr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
